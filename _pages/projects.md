---
layout: single
title: "Projects"
permalink: /projects/
sidebar:
  nav: main
---

## Current Projects

<br>

<details>
  <summary>
    <strong>InterVisions</strong> – Participatory AI for Intersectional Bias Auditing (2025–2026)  
    <br>
    <strong>Funding:</strong> EU – CERV &nbsp; | &nbsp; 
    <strong>Grant ID:</strong> 101214711 &nbsp; | &nbsp; 
    <strong>Budget:</strong> €245,417.34  
    <br><em style="color: #007acc; cursor: pointer;">More info</em>
  </summary>
  <br>

  <strong>Coordinated by:</strong> ALIA – Associació Cultural de Dones per a la Recerca i l’Acció <br>
  <strong>Participants:</strong><br>
  – <strong>Centre de Visió per Computador (CVC-UAB)</strong>, Research Organisation<br>
  – <strong>Diputació de Barcelona</strong>, Associated Partner<br><br>

  <strong>Goal:</strong><br>
  InterVisions aims to build a <strong>participatory bias audit tool</strong> for vision and language foundation models.  
  It integrates intersectional feminist theory, deep learning, and participatory AI practices to identify and mitigate social biases in large-scale multimodal AI systems.<br><br>

  <strong>Activities:</strong><br>
  – Community-driven workshops to audit foundation models<br>
  – Co-creation of a <strong>technical fairness benchmark</strong><br>
  – Development of <strong>intersectional impact assessment guidelines</strong><br>
  – Promotion of <strong>ethical AI practices</strong> in line with the EU Charter of Fundamental Rights<br><br>

  <strong>Keywords:</strong> Bias in AI, Ethical AI, Participatory AI, Intersectionality, Fairness Benchmark, Vision & Language Models<br><br>

  <strong>Project Website:</strong>  TBD

</details>

<br>

<details>
  <summary>
    <strong>FairCLIP</strong> – Training a Fair CLIP Model with Hybrid Real and Synthetic Data (2024–2025)<br>
    <strong>Funding:</strong> EuroHPC AI & Data-Intensive Applications Access Call &nbsp; | &nbsp;
    <strong>Grant ID:</strong> EHPC-AI-2024A02-040 &nbsp; | &nbsp;
    <strong>Resources:</strong> 32,000 node hours on MareNostrum5<br>
    <em style="color: #007acc; cursor: pointer;">More info</em>
  </summary>
  <br>

  <strong>Coordinated by:</strong> Universitat Autònoma de Barcelona / Computer Vision Center (Spain)<br>
  <strong>Team:</strong><br>
  – Dr. Lluis Gomez (PI) • Dr. Lei Kang • Dr. Mohamed Ali Souibgui • Mr. Francesc Net • Mr. Joan Masoliver • Dr. Sonia Ruiz • Prof. Yuki M. Asano (University of Amsterdam)<br><br>

  <strong>Objective:</strong><br>
  The <strong>FairCLIP</strong> project aims to mitigate bias in large-scale vision-language models by training a new CLIP model on a hybrid dataset combining real and synthetic data, ensuring balanced demographic representation. The project contributes to fairness in AI with both technical and ethical innovations.<br><br>

  <strong>Key Methods:</strong><br>
  – Synthetic data generation via state-of-the-art diffusion models<br>
  – Real data from the CommonPool dataset<br>
  – OpenCLIP framework for scalable training<br>
  – Contrastive learning with demographic control<br><br>

  <strong>Milestones:</strong><br>
  – Small-scale (12M samples), medium-scale (128M), and large-scale (400M) experiments<br>
  – Total: 32,000 node hours over 12 months (Aug 2024–Jul 2025)<br><br>

  <strong>Expected Outcomes:</strong><br>
  – A fairness-optimized CLIP model<br>
  – A reusable hybrid dataset<br>
  – Open-source technical deliverables<br><br>

  <strong>Keywords:</strong> Fair AI, CLIP, Synthetic Data, Bias Mitigation, Diffusion Models, Vision-Language Models, HPC<br><br>

  <strong>More Info:</strong>  
  <a href="https://pracecalls.eu/" target="_blank">EuroHPC Access Portal</a>  
</details>


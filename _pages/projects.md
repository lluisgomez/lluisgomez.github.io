---
layout: single
title: "Projects"
permalink: /projects/
sidebar:
  nav: main
---

## Current Projects

<br>

<details>
  <summary>
    <strong>InterVisions</strong> – Participatory AI for Intersectional Bias Auditing (2025–2026)  
    <br>
    <strong>Funding:</strong> EU – CERV &nbsp; | &nbsp; 
    <strong>Grant ID:</strong> 101214711 &nbsp; | &nbsp; 
    <strong>Budget:</strong> €245,417.34  
    <br><em style="color: #007acc; cursor: pointer;">More info</em>
  </summary>
  <br>

  <strong>Coordinated by:</strong> ALIA – Associació Cultural de Dones per a la Recerca i l’Acció <br>
  <strong>Participants:</strong><br>
  – <strong>Centre de Visió per Computador (CVC-UAB)</strong>, Research Organisation<br>
  – <strong>Diputació de Barcelona</strong>, Associated Partner<br><br>

  <strong>Goal:</strong><br>
  InterVisions aims to build a <strong>participatory bias audit tool</strong> for vision and language foundation models.  
  It integrates intersectional feminist theory, deep learning, and participatory AI practices to identify and mitigate social biases in large-scale multimodal AI systems.<br><br>

  <strong>Activities:</strong><br>
  – Community-driven workshops to audit foundation models<br>
  – Co-creation of a <strong>technical fairness benchmark</strong><br>
  – Development of <strong>intersectional impact assessment guidelines</strong><br>
  – Promotion of <strong>ethical AI practices</strong> in line with the EU Charter of Fundamental Rights<br><br>

  <strong>Keywords:</strong> Bias in AI, Ethical AI, Participatory AI, Intersectionality, Fairness Benchmark, Vision & Language Models<br><br>

  <strong>Project Website:</strong>  TBD

</details>

<br>

<details>
  <summary>
    <strong>FairCLIP</strong> – Training a Fair CLIP Model with Hybrid Real and Synthetic Data (2024–2025)<br>
    <strong>Funding:</strong> EuroHPC AI & Data-Intensive Applications Access Call &nbsp; | &nbsp;
    <strong>Grant ID:</strong> EHPC-AI-2024A02-040 &nbsp; | &nbsp;
    <strong>Resources:</strong> 32,000 node hours on MareNostrum5<br>
    <em style="color: #007acc; cursor: pointer;">More info</em>
  </summary>
  <br>

  <strong>Coordinated by:</strong> Universitat Autònoma de Barcelona / Computer Vision Center (Spain)<br>
  <strong>Team:</strong><br>
  – Dr. Lluis Gomez (PI) • Dr. Lei Kang • Dr. Mohamed Ali Souibgui • Mr. Francesc Net • Mr. Joan Masoliver • Dr. Sonia Ruiz • Prof. Yuki M. Asano (University of Amsterdam)<br><br>

  <strong>Objective:</strong><br>
  The <strong>FairCLIP</strong> project aims to mitigate bias in large-scale vision-language models by training a new CLIP model on a hybrid dataset combining real and synthetic data, ensuring balanced demographic representation. The project contributes to fairness in AI with both technical and ethical innovations.<br><br>

  <strong>Key Methods:</strong><br>
  – Synthetic data generation via state-of-the-art diffusion models<br>
  – Real data from the CommonPool dataset<br>
  – OpenCLIP framework for scalable training<br>
  – Contrastive learning with demographic control<br><br>

  <strong>Milestones:</strong><br>
  – Small-scale (12M samples), medium-scale (128M), and large-scale (400M) experiments<br>
  – Total: 32,000 node hours over 12 months (Aug 2024–Jul 2025)<br><br>

  <strong>Expected Outcomes:</strong><br>
  – A fairness-optimized CLIP model<br>
  – A reusable hybrid dataset<br>
  – Open-source technical deliverables<br><br>

  <strong>Keywords:</strong> Fair AI, CLIP, Synthetic Data, Bias Mitigation, Diffusion Models, Vision-Language Models, HPC<br><br>

  <strong>Code:</strong>  
  <a href="https://github.com/lluisgomez/FairCLIP" target="_blank">FairCLIP GitHub Repository</a>  
</details>

<br>

<details>
  <summary>
    <strong>COELI-IA</strong> – From Text to Media: A Paradigm Shift in Cultural Heritage Management (2023–2025)<br>
    <strong>Funding:</strong> INNOTEC R+D Grant (Catalonia) &nbsp; | &nbsp;
    <strong>Grant ID:</strong> RDECR20/EMT/1791/2021 &nbsp; | &nbsp;
    <strong>Budget:</strong> €195,530.02<br>
    <em style="color: #007acc; cursor: pointer;">More info</em>
  </summary>
  <br>

  <strong>Coordinated by:</strong> Nubilum SL (SME) <br>
  <strong>Research Partner:</strong> Centre de Visió per Computador (CVC), Universitat Autònoma de Barcelona<br><br>

  <strong>Objective:</strong><br>
  COELI-IA aims to revolutionize the management and dissemination of cultural heritage content by leveraging AI techniques. The project explores automatic classification, indexing, and enhanced accessibility for digital archives through multimodal models that can understand and connect text and media data.<br><br>

  <strong>Key Innovations:</strong><br>
  – Development of AI-driven cultural heritage content engines<br>
  – New interfaces and recommendation systems based on content relevance<br>
  – Fine-tuning of AI models for domain-specific archives<br><br>

  <strong>Funding Structure:</strong><br>
  – Total accepted budget: €195,530.02<br>
  – CVC share: €84,446.05 (43.19%)<br>
  – Nubilum SL share: €111,083.98 (56.81%)<br><br>

  <strong>Team:</strong><br>
  – Dr. Lluís Gómez (CVC Lead)  
  – Pep Casals Pug (Nubilum Lead)
  – Marc Folia Campos (Nubilum)  
  – Francesc Net Barnes (CVC research staff)<br><br>

  <strong>Keywords:</strong> Cultural Heritage, AI for Archives, Multimodal Indexing, Recommendation Systems, Computer Vision, NLP<br><br>

  <strong>More Info:</strong>  
  <a href="https://coeli.cat/" target="_blank">coeli.cat</a> • 
  <a href="https://cvc.uab.cat" target="_blank">cvc.uab.cat</a>
</details>


